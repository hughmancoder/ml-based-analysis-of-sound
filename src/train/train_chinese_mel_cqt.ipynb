{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "768c2137",
      "metadata": {},
      "source": [
        "Chinese Instrument (Mel+CQT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e94852f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: d:\\qingchaolaopian\\Instrument Sound\\GitHub\\ml-based-analysis-of-sound\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "root = Path.cwd()\n",
        "while root != root.parent and not (root / \"src\").exists():\n",
        "    root = root.parent\n",
        "if str(root) not in sys.path:\n",
        "    sys.path.insert(0, str(root))\n",
        "import torch\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "from src.train.utils_mel_cqt import multi_label_train_loop\n",
        "print(\"Repo root:\", root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0cd69649",
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_RUN = \"Chinese_mel_cqt_v1\"\n",
        "WEIGHTS_DIR = Path(f\"../models/saved_weights/{TRAIN_RUN}\")\n",
        "USE_CKPT = False  # True to resume from last.pt\n",
        "\n",
        "# MANIFEST_CSV = \"../../data/processed/train_mels.csv\",\n",
        "    \n",
        "MANIFEST_CSV = [\n",
        "    \"../../data/processed/train_mels.csv\",\n",
        "    \"../../data/processed/train_mels_mixed.csv\",\n",
        "]\n",
        "LABELS_YAML = \"../configs/labels.yaml\"\n",
        "AUDIO_CONFIG_YAML = \"../configs/audio_params.yaml\" \n",
        "\n",
        "CONFIG = {\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 1e-3,\n",
        "    \"epochs\": 300,\n",
        "    \"patience\": 30,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"dropout\": 0.5,\n",
        "    \"val_frac\": 0.2,\n",
        "    \"seed\": 1337,\n",
        "    \"threshold\": 0.5\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5b4a55e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 15 classes: strings, brass, percussion, woodwind, sheng, dizi, timpani, erhu, pipa, suona, guzheng, piano, guqin, xiao, yangqin\n",
            "Starting fresh (resume disabled).\n",
            "[1/300] Loss: 0.2802/0.2230 | Val MicroF1: 0.5571 | Time: 31.0s\n",
            "[2/300] Loss: 0.2284/0.1883 | Val MicroF1: 0.6532 | Time: 31.7s\n",
            "[3/300] Loss: 0.2081/0.1762 | Val MicroF1: 0.7018 | Time: 32.5s\n",
            "[4/300] Loss: 0.1940/0.1548 | Val MicroF1: 0.7374 | Time: 35.0s\n",
            "[5/300] Loss: 0.1840/0.1469 | Val MicroF1: 0.7547 | Time: 35.7s\n",
            "[6/300] Loss: 0.1744/0.1410 | Val MicroF1: 0.7699 | Time: 36.3s\n",
            "[7/300] Loss: 0.1677/0.1286 | Val MicroF1: 0.7899 | Time: 35.6s\n",
            "[8/300] Loss: 0.1600/0.1252 | Val MicroF1: 0.7975 | Time: 35.7s\n",
            "[9/300] Loss: 0.1567/0.1237 | Val MicroF1: 0.8025 | Time: 35.5s\n",
            "[10/300] Loss: 0.1537/0.1236 | Val MicroF1: 0.7968 | Time: 35.7s\n",
            "[11/300] Loss: 0.1513/0.1201 | Val MicroF1: 0.8067 | Time: 35.6s\n",
            "[12/300] Loss: 0.1489/0.1207 | Val MicroF1: 0.8040 | Time: 35.5s\n",
            "[13/300] Loss: 0.1473/0.1149 | Val MicroF1: 0.8117 | Time: 35.4s\n",
            "[14/300] Loss: 0.1430/0.1108 | Val MicroF1: 0.8189 | Time: 35.4s\n",
            "[15/300] Loss: 0.1391/0.1068 | Val MicroF1: 0.8276 | Time: 35.4s\n",
            "[16/300] Loss: 0.1362/0.1069 | Val MicroF1: 0.8297 | Time: 35.4s\n",
            "[17/300] Loss: 0.1363/0.1072 | Val MicroF1: 0.8283 | Time: 35.3s\n",
            "[18/300] Loss: 0.1356/0.1076 | Val MicroF1: 0.8311 | Time: 35.0s\n",
            "[19/300] Loss: 0.1334/0.1047 | Val MicroF1: 0.8297 | Time: 35.1s\n",
            "[20/300] Loss: 0.1319/0.1029 | Val MicroF1: 0.8313 | Time: 35.0s\n",
            "[21/300] Loss: 0.1301/0.0987 | Val MicroF1: 0.8463 | Time: 35.1s\n",
            "[22/300] Loss: 0.1264/0.1000 | Val MicroF1: 0.8420 | Time: 34.9s\n",
            "[23/300] Loss: 0.1268/0.0977 | Val MicroF1: 0.8454 | Time: 35.0s\n",
            "[24/300] Loss: 0.1264/0.0980 | Val MicroF1: 0.8481 | Time: 35.1s\n",
            "[25/300] Loss: 0.1256/0.0990 | Val MicroF1: 0.8495 | Time: 35.0s\n",
            "[26/300] Loss: 0.1236/0.0979 | Val MicroF1: 0.8408 | Time: 35.1s\n",
            "[27/300] Loss: 0.1243/0.0953 | Val MicroF1: 0.8498 | Time: 34.0s\n",
            "[28/300] Loss: 0.1223/0.0957 | Val MicroF1: 0.8554 | Time: 30.6s\n",
            "[29/300] Loss: 0.1213/0.0973 | Val MicroF1: 0.8488 | Time: 30.6s\n",
            "[30/300] Loss: 0.1222/0.0938 | Val MicroF1: 0.8525 | Time: 30.5s\n",
            "[31/300] Loss: 0.1210/0.0965 | Val MicroF1: 0.8499 | Time: 30.6s\n",
            "[32/300] Loss: 0.1193/0.0974 | Val MicroF1: 0.8492 | Time: 30.6s\n",
            "[33/300] Loss: 0.1184/0.0959 | Val MicroF1: 0.8481 | Time: 30.6s\n",
            "[34/300] Loss: 0.1177/0.0911 | Val MicroF1: 0.8607 | Time: 28.4s\n",
            "[35/300] Loss: 0.1165/0.0914 | Val MicroF1: 0.8567 | Time: 26.7s\n",
            "[36/300] Loss: 0.1155/0.0934 | Val MicroF1: 0.8589 | Time: 26.7s\n",
            "[37/300] Loss: 0.1152/0.0892 | Val MicroF1: 0.8616 | Time: 26.6s\n",
            "[38/300] Loss: 0.1146/0.0944 | Val MicroF1: 0.8521 | Time: 26.6s\n",
            "[39/300] Loss: 0.1144/0.0939 | Val MicroF1: 0.8553 | Time: 26.5s\n",
            "[40/300] Loss: 0.1123/0.0899 | Val MicroF1: 0.8596 | Time: 26.4s\n",
            "[41/300] Loss: 0.1129/0.0932 | Val MicroF1: 0.8552 | Time: 26.8s\n",
            "[42/300] Loss: 0.1109/0.0921 | Val MicroF1: 0.8613 | Time: 26.5s\n",
            "[43/300] Loss: 0.1096/0.0860 | Val MicroF1: 0.8694 | Time: 26.5s\n",
            "[44/300] Loss: 0.1065/0.0825 | Val MicroF1: 0.8746 | Time: 26.7s\n",
            "[45/300] Loss: 0.1080/0.0987 | Val MicroF1: 0.8491 | Time: 26.4s\n",
            "[46/300] Loss: 0.1091/0.0862 | Val MicroF1: 0.8675 | Time: 26.6s\n",
            "[47/300] Loss: 0.1081/0.0866 | Val MicroF1: 0.8704 | Time: 26.7s\n",
            "[48/300] Loss: 0.1078/0.0876 | Val MicroF1: 0.8663 | Time: 26.5s\n",
            "[49/300] Loss: 0.1064/0.0873 | Val MicroF1: 0.8654 | Time: 26.7s\n",
            "[50/300] Loss: 0.1062/0.0821 | Val MicroF1: 0.8771 | Time: 26.7s\n",
            "[51/300] Loss: 0.1056/0.0836 | Val MicroF1: 0.8753 | Time: 26.8s\n",
            "[52/300] Loss: 0.1044/0.0815 | Val MicroF1: 0.8772 | Time: 26.6s\n",
            "[53/300] Loss: 0.1039/0.0831 | Val MicroF1: 0.8742 | Time: 26.6s\n",
            "[54/300] Loss: 0.1032/0.0821 | Val MicroF1: 0.8767 | Time: 26.5s\n",
            "[55/300] Loss: 0.1021/0.0828 | Val MicroF1: 0.8742 | Time: 26.5s\n",
            "[56/300] Loss: 0.1024/0.0830 | Val MicroF1: 0.8721 | Time: 26.5s\n",
            "[57/300] Loss: 0.1008/0.0806 | Val MicroF1: 0.8774 | Time: 26.5s\n",
            "[58/300] Loss: 0.1012/0.0808 | Val MicroF1: 0.8793 | Time: 26.5s\n",
            "[59/300] Loss: 0.1011/0.0808 | Val MicroF1: 0.8804 | Time: 27.4s\n",
            "[60/300] Loss: 0.1003/0.0802 | Val MicroF1: 0.8816 | Time: 27.8s\n",
            "[61/300] Loss: 0.0995/0.0786 | Val MicroF1: 0.8834 | Time: 27.8s\n",
            "[62/300] Loss: 0.0988/0.0798 | Val MicroF1: 0.8803 | Time: 27.2s\n",
            "[63/300] Loss: 0.0990/0.0803 | Val MicroF1: 0.8793 | Time: 26.9s\n",
            "[64/300] Loss: 0.0986/0.0798 | Val MicroF1: 0.8814 | Time: 26.9s\n",
            "[65/300] Loss: 0.0990/0.0803 | Val MicroF1: 0.8801 | Time: 26.8s\n",
            "[66/300] Loss: 0.0965/0.0753 | Val MicroF1: 0.8909 | Time: 26.8s\n",
            "[67/300] Loss: 0.0962/0.0774 | Val MicroF1: 0.8851 | Time: 26.8s\n",
            "[68/300] Loss: 0.0960/0.0773 | Val MicroF1: 0.8860 | Time: 27.0s\n",
            "[69/300] Loss: 0.0966/0.0804 | Val MicroF1: 0.8758 | Time: 27.5s\n",
            "[70/300] Loss: 0.0960/0.0799 | Val MicroF1: 0.8800 | Time: 27.0s\n",
            "[71/300] Loss: 0.0951/0.0763 | Val MicroF1: 0.8873 | Time: 26.9s\n",
            "[72/300] Loss: 0.0955/0.0778 | Val MicroF1: 0.8821 | Time: 26.7s\n",
            "[73/300] Loss: 0.0959/0.0780 | Val MicroF1: 0.8819 | Time: 26.8s\n",
            "[74/300] Loss: 0.0919/0.0740 | Val MicroF1: 0.8906 | Time: 26.7s\n",
            "[75/300] Loss: 0.0921/0.0774 | Val MicroF1: 0.8875 | Time: 26.7s\n",
            "[76/300] Loss: 0.0947/0.0771 | Val MicroF1: 0.8852 | Time: 26.7s\n",
            "[77/300] Loss: 0.0943/0.0774 | Val MicroF1: 0.8823 | Time: 26.8s\n",
            "[78/300] Loss: 0.0935/0.0747 | Val MicroF1: 0.8911 | Time: 26.9s\n",
            "[79/300] Loss: 0.0933/0.0756 | Val MicroF1: 0.8901 | Time: 26.7s\n",
            "[80/300] Loss: 0.0966/0.0768 | Val MicroF1: 0.8837 | Time: 26.7s\n",
            "[81/300] Loss: 0.0955/0.0767 | Val MicroF1: 0.8870 | Time: 26.7s\n",
            "[82/300] Loss: 0.0942/0.0761 | Val MicroF1: 0.8869 | Time: 26.9s\n",
            "[83/300] Loss: 0.0927/0.0746 | Val MicroF1: 0.8896 | Time: 26.8s\n",
            "[84/300] Loss: 0.0919/0.0783 | Val MicroF1: 0.8836 | Time: 27.0s\n",
            "[85/300] Loss: 0.0918/0.0757 | Val MicroF1: 0.8872 | Time: 27.0s\n",
            "[86/300] Loss: 0.0911/0.0731 | Val MicroF1: 0.8946 | Time: 27.0s\n",
            "[87/300] Loss: 0.0880/0.0731 | Val MicroF1: 0.8936 | Time: 27.0s\n",
            "[88/300] Loss: 0.0877/0.0721 | Val MicroF1: 0.8940 | Time: 26.9s\n",
            "[89/300] Loss: 0.0876/0.0736 | Val MicroF1: 0.8904 | Time: 27.1s\n",
            "[90/300] Loss: 0.0875/0.0740 | Val MicroF1: 0.8901 | Time: 27.0s\n",
            "[91/300] Loss: 0.0874/0.0719 | Val MicroF1: 0.8918 | Time: 27.2s\n",
            "[92/300] Loss: 0.0882/0.0726 | Val MicroF1: 0.8908 | Time: 27.2s\n",
            "[93/300] Loss: 0.0876/0.0728 | Val MicroF1: 0.8909 | Time: 26.9s\n",
            "[94/300] Loss: 0.0865/0.0701 | Val MicroF1: 0.8987 | Time: 26.7s\n",
            "[95/300] Loss: 0.0848/0.0698 | Val MicroF1: 0.8996 | Time: 26.7s\n",
            "[96/300] Loss: 0.0851/0.0715 | Val MicroF1: 0.8961 | Time: 26.8s\n",
            "[97/300] Loss: 0.0846/0.0703 | Val MicroF1: 0.8966 | Time: 26.8s\n",
            "[98/300] Loss: 0.0884/0.0746 | Val MicroF1: 0.8886 | Time: 27.0s\n",
            "[99/300] Loss: 0.0883/0.0720 | Val MicroF1: 0.8938 | Time: 26.9s\n",
            "[100/300] Loss: 0.0875/0.0722 | Val MicroF1: 0.8946 | Time: 27.0s\n",
            "[101/300] Loss: 0.0868/0.0722 | Val MicroF1: 0.8942 | Time: 26.8s\n",
            "[102/300] Loss: 0.0867/0.0746 | Val MicroF1: 0.8902 | Time: 26.7s\n",
            "[103/300] Loss: 0.0862/0.0726 | Val MicroF1: 0.8927 | Time: 26.9s\n",
            "[104/300] Loss: 0.0859/0.0719 | Val MicroF1: 0.8934 | Time: 26.8s\n",
            "[105/300] Loss: 0.0838/0.0719 | Val MicroF1: 0.8939 | Time: 27.0s\n",
            "[106/300] Loss: 0.0872/0.0732 | Val MicroF1: 0.8929 | Time: 26.7s\n",
            "[107/300] Loss: 0.0866/0.0728 | Val MicroF1: 0.8912 | Time: 26.7s\n",
            "[108/300] Loss: 0.0859/0.0712 | Val MicroF1: 0.8955 | Time: 26.8s\n",
            "[109/300] Loss: 0.0854/0.0710 | Val MicroF1: 0.8939 | Time: 27.1s\n",
            "[110/300] Loss: 0.0852/0.0743 | Val MicroF1: 0.8898 | Time: 26.9s\n",
            "[111/300] Loss: 0.0844/0.0710 | Val MicroF1: 0.8959 | Time: 26.8s\n",
            "[112/300] Loss: 0.0843/0.0699 | Val MicroF1: 0.8996 | Time: 27.1s\n",
            "[113/300] Loss: 0.0842/0.0748 | Val MicroF1: 0.8877 | Time: 22.9s\n",
            "[114/300] Loss: 0.0838/0.0729 | Val MicroF1: 0.8914 | Time: 21.7s\n",
            "[115/300] Loss: 0.0840/0.0765 | Val MicroF1: 0.8831 | Time: 21.7s\n",
            "[116/300] Loss: 0.0830/0.0726 | Val MicroF1: 0.8929 | Time: 21.6s\n",
            "[117/300] Loss: 0.0832/0.0710 | Val MicroF1: 0.8970 | Time: 21.2s\n",
            "[118/300] Loss: 0.0836/0.0712 | Val MicroF1: 0.8951 | Time: 20.8s\n",
            "[119/300] Loss: 0.0831/0.0698 | Val MicroF1: 0.8996 | Time: 20.8s\n",
            "[120/300] Loss: 0.0820/0.0699 | Val MicroF1: 0.8969 | Time: 20.9s\n",
            "[121/300] Loss: 0.0830/0.0723 | Val MicroF1: 0.8933 | Time: 20.8s\n",
            "[122/300] Loss: 0.0828/0.0705 | Val MicroF1: 0.8983 | Time: 21.5s\n",
            "[123/300] Loss: 0.0830/0.0702 | Val MicroF1: 0.8963 | Time: 21.5s\n",
            "[124/300] Loss: 0.0816/0.0702 | Val MicroF1: 0.8972 | Time: 20.9s\n",
            "[125/300] Loss: 0.0826/0.0697 | Val MicroF1: 0.9004 | Time: 21.2s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExisting weights detected. Resuming from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresume_ckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m results = \u001b[43mmulti_label_train_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanifest_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMANIFEST_CSV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWEIGHTS_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval_frac\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpatience\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreshold\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43maudio_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudio_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_ckpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_best_stamped\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[32m     38\u001b[39m history = results[\u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\qingchaolaopian\\Instrument Sound\\GitHub\\ml-based-analysis-of-sound\\src\\train\\utils_mel_cqt.py:227\u001b[39m, in \u001b[36mmulti_label_train_loop\u001b[39m\u001b[34m(manifest_csv, classes, ckpt_dir, epochs, batch_size, lr, weight_decay, val_frac, dropout, patience, num_workers, threshold, seed, audio_cfg, resume_from, save_best_stamped, in_ch)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m    226\u001b[39m     t0 = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     train_loss, train_m = \u001b[43mtrain_one_epoch_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_mps_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_mem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     val_loss, val_m = evaluate_multi(model, val_loader, criterion, device, use_cuda_amp, use_mps_amp, pin_mem, threshold)\n\u001b[32m    230\u001b[39m     scheduler.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\qingchaolaopian\\Instrument Sound\\GitHub\\ml-based-analysis-of-sound\\src\\train\\utils_mel_cqt.py:138\u001b[39m, in \u001b[36mtrain_one_epoch_multi\u001b[39m\u001b[34m(model, loader, criterion, optimizer, scaler, device, use_cuda_amp, use_mps_amp, pin_mem, threshold)\u001b[39m\n\u001b[32m    136\u001b[39m     scaler.scale(loss).backward()\n\u001b[32m    137\u001b[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m5.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     scaler.update()\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\qingchaolaopian\\Instrument Sound\\GitHub\\ml-based-analysis-of-sound\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:478\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) == \u001b[32m0\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\qingchaolaopian\\Instrument Sound\\GitHub\\ml-based-analysis-of-sound\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:371\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    364\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    365\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m     **kwargs: Any,\n\u001b[32m    369\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    370\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    372\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\qingchaolaopian\\Instrument Sound\\GitHub\\ml-based-analysis-of-sound\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:371\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    364\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    365\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m     **kwargs: Any,\n\u001b[32m    369\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    370\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    372\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "with open(AUDIO_CONFIG_YAML, 'r', encoding='utf-8') as f:\n",
        "    audio_params = yaml.safe_load(f)\n",
        "with open(LABELS_YAML, 'r', encoding='utf-8') as f:\n",
        "    label_config = yaml.safe_load(f)\n",
        "    classes = [c.strip().lower() for c in label_config.get('train_labels', [])]\n",
        "print(f\"Loaded {len(classes)} classes: {', '.join(classes)}\")\n",
        "\n",
        "\n",
        "resume_ckpt = WEIGHTS_DIR / \"last.pt\" if USE_CKPT else None\n",
        "if resume_ckpt is None:\n",
        "    print(\"Starting fresh (resume disabled).\")\n",
        "elif not resume_ckpt.exists():\n",
        "    resume_ckpt = None\n",
        "    print(\"Starting fresh. No previous weights found.\")\n",
        "else:\n",
        "    print(f\"Existing weights detected. Resuming from {resume_ckpt}\")\n",
        "\n",
        "results = multi_label_train_loop(\n",
        "    manifest_csv=MANIFEST_CSV,\n",
        "    classes=classes,\n",
        "    ckpt_dir=WEIGHTS_DIR,\n",
        "    epochs=CONFIG[\"epochs\"],\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    lr=CONFIG[\"lr\"],\n",
        "    weight_decay=CONFIG[\"weight_decay\"],\n",
        "    val_frac=CONFIG[\"val_frac\"],\n",
        "    dropout=CONFIG[\"dropout\"],\n",
        "    patience=CONFIG[\"patience\"],\n",
        "    num_workers=0,\n",
        "    threshold=CONFIG[\"threshold\"],\n",
        "    seed=CONFIG[\"seed\"],\n",
        "    audio_cfg=audio_params['audio'],\n",
        "    resume_from=resume_ckpt,\n",
        "    save_best_stamped=False,\n",
        ")\n",
        "    \n",
        "# Run the training\n",
        "history = results[\"history\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d164ffe8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.train.utils import plot_metrics\n",
        "\n",
        "WEIGHTS_DIR = Path(f\"../models/saved_weights/{TRAIN_RUN}\")\n",
        "MODEL_WEIGHTS = Path(WEIGHTS_DIR / \"last.pt\")\n",
        "ckpt_loaded = torch.load(MODEL_WEIGHTS, map_location=\"cpu\")\n",
        "audio_params = ckpt_loaded['audio_config']\n",
        "history = ckpt_loaded[\"history\"]\n",
        "plot_metrics(history)\n",
        "\n",
        "print(\"Audio Config used during training:\")\n",
        "print(audio_params)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
